{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bituspenvconda3aaf4a122e974252b54ca0bba236eb6c",
   "display_name": "Python 3.7.7 64-bit ('uspenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               Tweet   Creation_date  \\\n",
       "0  Minha fam√≠lia √© louca demais kkk\\nMeu tio perg...     Pablo Lemes   \n",
       "1  Se √© azul e fala, s√≥ pode ser uma arara https:...    MMD&Doider üíÉ   \n",
       "2  E ontem o cara me aparece com uma arara azul n...     Vanderson ü¶Ö   \n",
       "3  @hallwayghost KAKAKKAKA a arara azul era de um...  duda ‚Ä¢ üìñ: hdo‚Åµ   \n",
       "4  @twentyhalpert eu moro interior to acostumada ...          p√¢mela   \n",
       "\n",
       "            Name              User               location  retweets  \\\n",
       "0     sou_pablo2  29/11/2020 18:01       Bras√≠lia, Brasil         0   \n",
       "1   BeckieApenas  29/11/2020 17:18         Manaus, Brazil         0   \n",
       "2       Vaandoo_  29/11/2020 14:55  S√£o Bernardo do Campo         0   \n",
       "3  twentyhalpert  29/11/2020 03:44                    NaN         0   \n",
       "4   hallwayghost  29/11/2020 03:40              üè° = frens         0   \n",
       "\n",
       "   favorites  friends_count  followers_count  Classification  \n",
       "0          1            271              244              -1  \n",
       "1          0            192              105               0  \n",
       "2          1            376              577              -1  \n",
       "3          0           6652             6693              -1  \n",
       "4          0            586              641               0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Creation_date</th>\n      <th>Name</th>\n      <th>User</th>\n      <th>location</th>\n      <th>retweets</th>\n      <th>favorites</th>\n      <th>friends_count</th>\n      <th>followers_count</th>\n      <th>Classification</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Minha fam√≠lia √© louca demais kkk\\nMeu tio perg...</td>\n      <td>Pablo Lemes</td>\n      <td>sou_pablo2</td>\n      <td>29/11/2020 18:01</td>\n      <td>Bras√≠lia, Brasil</td>\n      <td>0</td>\n      <td>1</td>\n      <td>271</td>\n      <td>244</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Se √© azul e fala, s√≥ pode ser uma arara https:...</td>\n      <td>MMD&amp;Doider üíÉ</td>\n      <td>BeckieApenas</td>\n      <td>29/11/2020 17:18</td>\n      <td>Manaus, Brazil</td>\n      <td>0</td>\n      <td>0</td>\n      <td>192</td>\n      <td>105</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E ontem o cara me aparece com uma arara azul n...</td>\n      <td>Vanderson ü¶Ö</td>\n      <td>Vaandoo_</td>\n      <td>29/11/2020 14:55</td>\n      <td>S√£o Bernardo do Campo</td>\n      <td>0</td>\n      <td>1</td>\n      <td>376</td>\n      <td>577</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@hallwayghost KAKAKKAKA a arara azul era de um...</td>\n      <td>duda ‚Ä¢ üìñ: hdo‚Åµ</td>\n      <td>twentyhalpert</td>\n      <td>29/11/2020 03:44</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6652</td>\n      <td>6693</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@twentyhalpert eu moro interior to acostumada ...</td>\n      <td>p√¢mela</td>\n      <td>hallwayghost</td>\n      <td>29/11/2020 03:40</td>\n      <td>üè° = frens</td>\n      <td>0</td>\n      <td>0</td>\n      <td>586</td>\n      <td>641</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Datasets\\AraraAzul_Class_20201129.csv\", delimiter=\";\", encoding=\"utf-8\") # Utiliza√ß√£o do dataset classificado manualmente com os Tweets\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o dos Embeddings\n",
    "\n",
    "from gensim import corpora\n",
    "\n",
    "# Importando os Embeddings e transformando num array\n",
    "\n",
    "## tf-idf\n",
    "\n",
    "tf_idf_emb = corpora.MmCorpus('Embeddings\\TF_IDF\\matriz_tfidf.mm')\n",
    "tf_idf_emb = gensim.matutils.corpus2csc(tf_idf_emb)\n",
    "tf_idf_emb = tf_idf_emb.T.toarray()\n",
    "\n",
    "## LSA\n",
    "\n",
    "lsa_emb_50 = corpora.MmCorpus('Embeddings\\LSA_LSI\\matriz_lsi_lsa_50.mm')\n",
    "lsa_emb_100 = corpora.MmCorpus('Embeddings\\LSA_LSI\\matriz_lsi_lsa_100.mm')\n",
    "lsa_emb_150 = corpora.MmCorpus('Embeddings\\LSA_LSI\\matriz_lsi_lsa_150.mm')\n",
    "lsa_emb_200 = corpora.MmCorpus('Embeddings\\LSA_LSI\\matriz_lsi_lsa_200.mm')\n",
    "lsa_emb_250 = corpora.MmCorpus('Embeddings\\LSA_LSI\\matriz_lsi_lsa_250.mm')\n",
    "lsa_emb_300 = corpora.MmCorpus('Embeddings\\LSA_LSI\\matriz_lsi_lsa_300.mm')\n",
    "\n",
    "lsa_emb_50 = gensim.matutils.corpus2csc(lsa_emb_50)\n",
    "lsa_emb_100 = gensim.matutils.corpus2csc(lsa_emb_100)\n",
    "lsa_emb_150 = gensim.matutils.corpus2csc(lsa_emb_150)\n",
    "lsa_emb_200 = gensim.matutils.corpus2csc(lsa_emb_200)\n",
    "lsa_emb_250 = gensim.matutils.corpus2csc(lsa_emb_250)\n",
    "lsa_emb_300 = gensim.matutils.corpus2csc(lsa_emb_300)\n",
    "\n",
    "lsa_emb_50 = lsa_emb_50.T.toarray()\n",
    "lsa_emb_100 = lsa_emb_100.T.toarray()\n",
    "lsa_emb_150 = lsa_emb_150.T.toarray()\n",
    "lsa_emb_200 = lsa_emb_200.T.toarray()\n",
    "lsa_emb_250 = lsa_emb_250.T.toarray()\n",
    "lsa_emb_300 = lsa_emb_300.T.toarray()\n",
    "\n",
    "\n",
    "## TopicLSA\n",
    "\n",
    "Topic_LSA_emb_50 = corpora.MmCorpus('Embeddings\\TOPIC_LSA\\Topic_lsa_50.mm')\n",
    "Topic_LSA_emb_100 = corpora.MmCorpus('Embeddings\\TOPIC_LSA\\Topic_lsa_100.mm')\n",
    "Topic_LSA_emb_150 = corpora.MmCorpus('Embeddings\\TOPIC_LSA\\Topic_lsa_150.mm')\n",
    "Topic_LSA_emb_200 = corpora.MmCorpus('Embeddings\\TOPIC_LSA\\Topic_lsa_200.mm')\n",
    "Topic_LSA_emb_250 = corpora.MmCorpus('Embeddings\\TOPIC_LSA\\Topic_lsa_250.mm')\n",
    "Topic_LSA_emb_300 = corpora.MmCorpus('Embeddings\\TOPIC_LSA\\Topic_lsa_300.mm')\n",
    "\n",
    "Topic_LSA_emb_50 = gensim.matutils.corpus2csc(Topic_LSA_emb_50)\n",
    "Topic_LSA_emb_100 = gensim.matutils.corpus2csc(Topic_LSA_emb_100)\n",
    "Topic_LSA_emb_150 = gensim.matutils.corpus2csc(Topic_LSA_emb_150)\n",
    "Topic_LSA_emb_200 = gensim.matutils.corpus2csc(Topic_LSA_emb_200)\n",
    "Topic_LSA_emb_250 = gensim.matutils.corpus2csc(Topic_LSA_emb_250)\n",
    "Topic_LSA_emb_300 = gensim.matutils.corpus2csc(Topic_LSA_emb_300)\n",
    "\n",
    "Topic_LSA_emb_50 = Topic_LSA_emb_50.T.toarray()\n",
    "Topic_LSA_emb_100 = Topic_LSA_emb_100.T.toarray()\n",
    "Topic_LSA_emb_150 = Topic_LSA_emb_150.T.toarray()\n",
    "Topic_LSA_emb_200 = Topic_LSA_emb_200.T.toarray()\n",
    "Topic_LSA_emb_250 = Topic_LSA_emb_250.T.toarray()\n",
    "Topic_LSA_emb_300 = Topic_LSA_emb_300.T.toarray()\n",
    "\n",
    "## LDA\n",
    "\n",
    "lda_emb_50 = corpora.MmCorpus('Embeddings\\LDA\\Lda_model_50.mm')\n",
    "lda_emb_100 = corpora.MmCorpus('Embeddings\\LDA\\Lda_model_100.mm')\n",
    "lda_emb_150 = corpora.MmCorpus('Embeddings\\LDA\\Lda_model_150.mm')\n",
    "lda_emb_200 = corpora.MmCorpus('Embeddings\\LDA\\Lda_model_200.mm')\n",
    "lda_emb_250 = corpora.MmCorpus('Embeddings\\LDA\\Lda_model_250.mm')\n",
    "lda_emb_300 = corpora.MmCorpus('Embeddings\\LDA\\Lda_model_300.mm')\n",
    "\n",
    "lda_emb_50 = gensim.matutils.corpus2csc(lda_emb_50)\n",
    "lda_emb_100 = gensim.matutils.corpus2csc(lda_emb_100)\n",
    "lda_emb_150 = gensim.matutils.corpus2csc(lda_emb_150)\n",
    "lda_emb_200 = gensim.matutils.corpus2csc(lda_emb_200)\n",
    "lda_emb_250 = gensim.matutils.corpus2csc(lda_emb_250)\n",
    "lda_emb_300 = gensim.matutils.corpus2csc(lda_emb_300)\n",
    "\n",
    "lda_emb_50 = lda_emb_50.T.toarray()\n",
    "lda_emb_100 = lda_emb_100.T.toarray()\n",
    "lda_emb_150 = lda_emb_150.T.toarray()\n",
    "lda_emb_200 = lda_emb_200.T.toarray()\n",
    "lda_emb_250 = lda_emb_250.T.toarray()\n",
    "lda_emb_300 = lda_emb_300.T.toarray()\n"
   ]
  },
  {
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "target = dataset.iloc[:, -1].values\n",
    "\n",
    "def NaiveBayesmodel(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    Acuracia = accuracy_score(y_test, y_pred)\n",
    "    return(Acuracia)\n",
    "\n",
    "def RandomForest(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    Acuracia = accuracy_score(y_test, y_pred)\n",
    "    return(Acuracia)\n",
    "\n",
    "\n",
    "def SvmKernel(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    Acuracia = accuracy_score(y_test, y_pred)\n",
    "    return(Acuracia)\n",
    "\n",
    "def SvmKernel_linear(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    Acuracia = accuracy_score(y_test, y_pred)\n",
    "    return(Acuracia)\n",
    "\n",
    "def SvmKernel_sigmoid(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    classifier = SVC(kernel = 'sigmoid', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    Acuracia = accuracy_score(y_test, y_pred)\n",
    "    return(Acuracia)\n",
    "\n",
    "def LogReg(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    Acuracia = accuracy_score(y_test, y_pred)\n",
    "    return(Acuracia)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding: tfidf \n  Naive Bayes  0.7021276595744681  \n  Random Forest  0.7659574468085106  \n  SVM Kernel RBF  0.7872340425531915  \n  Regress√£o Log√≠stica  0.7872340425531915  \n\n"
     ]
    }
   ],
   "source": [
    "Embed_tfidf=[tf_idf_emb]\n",
    "Embed_lsa=[lsa_emb_50, lsa_emb_100, lsa_emb_150, lsa_emb_200, lsa_emb_250, lsa_emb_300]\n",
    "Embed_Topic=[Topic_LSA_emb_50, Topic_LSA_emb_100, Topic_LSA_emb_150, Topic_LSA_emb_200, Topic_LSA_emb_250, Topic_LSA_emb_300]\n",
    "Embed_lda=[lda_emb_50, lda_emb_100, lda_emb_150, lda_emb_200, lda_emb_250, lda_emb_300]\n",
    "\n",
    "for ff in Embed_tfidf:\n",
    "    nb = NaiveBayesmodel(ff, target)\n",
    "    rf = RandomForest(ff, target)\n",
    "    svm_r = SvmKernel(ff, target)\n",
    "    svm_l = SvmKernel(ff, target)\n",
    "    svm_s = SvmKernel(ff, target)\n",
    "    rl = LogReg(ff, target)\n",
    "    print (\"Embedding: tfidf \\n\",\" Naive Bayes \",nb,\" \\n\",\" Random Forest \",rf,\" \\n\",\" SVM Kernel RBF \",svm_r,\" \\n\",\" Regress√£o Log√≠stica \",rl,\" \\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding: LSA \n",
      "  Naive Bayes  0.574468085106383  \n",
      "  Random Forest  0.723404255319149  \n",
      "  SVM Kernel RBF  0.7659574468085106  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: LSA \n",
      "  Naive Bayes  0.5531914893617021  \n",
      "  Random Forest  0.6808510638297872  \n",
      "  SVM Kernel RBF  0.7659574468085106  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: LSA \n",
      "  Naive Bayes  0.2127659574468085  \n",
      "  Random Forest  0.7872340425531915  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: LSA \n",
      "  Naive Bayes  0.23404255319148937  \n",
      "  Random Forest  0.7021276595744681  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: LSA \n",
      "  Naive Bayes  0.2553191489361702  \n",
      "  Random Forest  0.7872340425531915  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: LSA \n",
      "  Naive Bayes  0.2553191489361702  \n",
      "  Random Forest  0.7872340425531915  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ff in Embed_lsa:\n",
    "    nb = NaiveBayesmodel(ff, target)\n",
    "    rf = RandomForest(ff, target)\n",
    "    svm_r = SvmKernel(ff, target)\n",
    "    svm_l = SvmKernel(ff, target)\n",
    "    svm_s = SvmKernel(ff, target)\n",
    "    rl = LogReg(ff, target)\n",
    "    print (\"Embedding: LSA \\n\",\" Naive Bayes \",nb,\" \\n\",\" Random Forest \",rf,\" \\n\",\" SVM Kernel RBF \",svm_r,\" \\n\",\" Regress√£o Log√≠stica \",rl,\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding: LsaTopic \n",
      "  Naive Bayes  0.3191489361702128  \n",
      "  Random Forest  0.6382978723404256  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.6808510638297872  \n",
      "\n",
      "Embedding: LsaTopic \n",
      "  Naive Bayes  0.44680851063829785  \n",
      "  Random Forest  0.6595744680851063  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7021276595744681  \n",
      "\n",
      "Embedding: LsaTopic \n",
      "  Naive Bayes  0.5106382978723404  \n",
      "  Random Forest  0.6808510638297872  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7021276595744681  \n",
      "\n",
      "Embedding: LsaTopic \n",
      "  Naive Bayes  0.3829787234042553  \n",
      "  Random Forest  0.7659574468085106  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7446808510638298  \n",
      "\n",
      "Embedding: LsaTopic \n",
      "  Naive Bayes  0.40425531914893614  \n",
      "  Random Forest  0.7021276595744681  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7446808510638298  \n",
      "\n",
      "Embedding: LsaTopic \n",
      "  Naive Bayes  0.40425531914893614  \n",
      "  Random Forest  0.7446808510638298  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7446808510638298  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ff in Embed_Topic:\n",
    "    nb = NaiveBayesmodel(ff, target)\n",
    "    rf = RandomForest(ff, target)\n",
    "    svm_r = SvmKernel(ff, target)\n",
    "    svm_l = SvmKernel(ff, target)\n",
    "    svm_s = SvmKernel(ff, target)\n",
    "    rl = LogReg(ff, target)\n",
    "    print (\"Embedding: LsaTopic \\n\",\" Naive Bayes \",nb,\" \\n\",\" Random Forest \",rf,\" \\n\",\" SVM Kernel RBF \",svm_r,\" \\n\",\" Regress√£o Log√≠stica \",rl,\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Embedding: Lda \n",
      "  Naive Bayes  0.3404255319148936  \n",
      "  Random Forest  0.723404255319149  \n",
      "  SVM Kernel RBF  0.7446808510638298  \n",
      "  Regress√£o Log√≠stica  0.7659574468085106  \n",
      "\n",
      "Embedding: Lda \n",
      "  Naive Bayes  0.2553191489361702  \n",
      "  Random Forest  0.8297872340425532  \n",
      "  SVM Kernel RBF  0.8085106382978723  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: Lda \n",
      "  Naive Bayes  0.23404255319148937  \n",
      "  Random Forest  0.8085106382978723  \n",
      "  SVM Kernel RBF  0.8085106382978723  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: Lda \n",
      "  Naive Bayes  0.2127659574468085  \n",
      "  Random Forest  0.8085106382978723  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n",
      "Embedding: Lda \n",
      "  Naive Bayes  0.23404255319148937  \n",
      "  Random Forest  0.6808510638297872  \n",
      "  SVM Kernel RBF  0.8085106382978723  \n",
      "  Regress√£o Log√≠stica  0.7659574468085106  \n",
      "\n",
      "Embedding: Lda \n",
      "  Naive Bayes  0.19148936170212766  \n",
      "  Random Forest  0.723404255319149  \n",
      "  SVM Kernel RBF  0.7872340425531915  \n",
      "  Regress√£o Log√≠stica  0.7872340425531915  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ff in Embed_lda:\n",
    "    nb = NaiveBayesmodel(ff, target)\n",
    "    rf = RandomForest(ff, target)\n",
    "    svm_r = SvmKernel(ff, target)\n",
    "    svm_l = SvmKernel(ff, target)\n",
    "    svm_s = SvmKernel(ff, target)\n",
    "    rl = LogReg(ff, target)\n",
    "    print (\"Embedding: Lda \\n\",\" Naive Bayes \",nb,\" \\n\",\" Random Forest \",rf,\" \\n\",\" SVM Kernel RBF \",svm_r,\" \\n\",\" Regress√£o Log√≠stica \",rl,\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}